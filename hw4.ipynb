{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9/25/19 Requirement   Group 24\n",
    "\n",
    "#      We have shrunk a little, and now have just 28 teams, so I'm\n",
    "# changing the experimental design structure a little.  The next\n",
    "# assignment is due Thursday, Oct. 10.\n",
    "\n",
    "#      There will be no class on Monday, Oct. 7, since Duke is on Fall Break.\n",
    "\n",
    "#       The RA asks that you report your results using the attached\n",
    "# template.  I also attach an updated spreadsheet for the teams.  If\n",
    "# anyone is still in a singleton team, please let me know and I shall\n",
    "# match you up with a team from your university.\n",
    "\n",
    "#       The assignment is to train with four hidden layers, each having\n",
    "# 1,024 nodes.  The activation function will be ReLU for the top two\n",
    "# layers, and linear for the bottom two layers (these lowest layer\n",
    "# receives the inputs).  We shall consider four datasets: MNIST fashion,\n",
    "# Cifar-10, cat/non-cat, and street view of digits. All groups will train\n",
    "# with 1,000 minibatches of size 128 for a total of 128,000 observations.\n",
    "\n",
    "#       The experiment will compare CNNs to regular NNs.  Teams doing CNNs\n",
    "# should use the kernel shown on slide 4 of dl6.pdf (which will be posted\n",
    "# later today).  You will also want to use zero padding, as discussed on\n",
    "# slide 14.\n",
    "\n",
    "# If your team's row number in the spreadsheet ends with a 1, use regular\n",
    "# a regular NN with the MNIST fashion data.\n",
    "\n",
    "# If it ends with a 2, use regular NN with the Cifar-10 data.\n",
    "\n",
    "# If it ends with a 3, use regular NN with the cat/non-cat data.\n",
    "\n",
    "# If 4, use regular NN with the street view of digits data.\n",
    "\n",
    "# If 5, use CNN with the MNIST fashion data.\n",
    "\n",
    "# If 6, use CNN with Cifar-10.\n",
    "\n",
    "# If 7, use CNN with cat/non-cat.\n",
    "\n",
    "# If 8, use CNN with streetview.\n",
    "\n",
    "# If 9, use CNN with Cifar-10, but use linear activation in only the first\n",
    "# hidden layer, and ReLU in the top three hidden layers.\n",
    "\n",
    "# If 0, use CNN with Cifar-10, but have five hidden layers, such that the\n",
    "# bottom two are linear and the top three are ReLU.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#set up seed\n",
    "#https://machinelearningmastery.com/reproducible-results-neural-networks-keras/\n",
    "from numpy.random import seed\n",
    "seed(23)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(34)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3, 73257)\n",
      "(32, 32, 3, 531131)\n",
      "(73257, 1)\n",
      "(531131, 1)\n",
      "(32, 32, 3, 604388)\n",
      "(604388, 1)\n",
      "(32, 32, 3, 26032)\n",
      "(26032, 1)\n",
      "[ 1  2  3  4  5  6  7  8  9 10]\n",
      "(604388, 3072)\n",
      "(26032, 3072)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 604388)\n",
      "128000\n",
      "128000\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Epoch 1/2\n",
      "128000/128000 [==============================] - 132s 1ms/step - loss: 13.3340 - acc: 0.1719\n",
      "Epoch 2/2\n",
      "128000/128000 [==============================] - 116s 905us/step - loss: 13.3447 - acc: 0.1721\n",
      "26032/26032 [==============================] - 5s 195us/step\n",
      "test_acc: 0.1958743085433313\n",
      "test_loss: 12.960974645819778\n",
      "Weights for 1st hidden layer\n",
      "[[ 0.03287894 -0.01961638 -0.00676601 ... -0.02203188 -0.00179878\n",
      "  -0.03352737]\n",
      " [ 0.02568968 -0.03190538  0.0069748  ...  0.03534507 -0.02867789\n",
      "  -0.01155834]\n",
      " [ 0.03051473  0.03034975  0.00331167 ... -0.01055502 -0.02858113\n",
      "  -0.026676  ]\n",
      " ...\n",
      " [-0.00781     0.03239557  0.01158051 ...  0.01239249 -0.02546391\n",
      "  -0.02103624]\n",
      " [ 0.00087753  0.03487987  0.03365701 ... -0.01658826  0.03081007\n",
      "  -0.01742562]\n",
      " [-0.03488891  0.03067526  0.02412577 ... -0.03101038  0.01185026\n",
      "  -0.02036925]]\n",
      "Intercept for 1st hidden layer\n",
      "[-0.0031609  -0.00316189  0.00316057 ...  0.00316135  0.00314881\n",
      " -0.00316203]\n",
      "Weights for 2nd hidden layer\n",
      "[[-0.01589161  0.0301345   0.05057371 ...  0.01906406  0.00819227\n",
      "  -0.0338927 ]\n",
      " [-0.04594561 -0.04605258 -0.02134074 ...  0.02300194  0.02635463\n",
      "   0.03966954]\n",
      " [ 0.03031233 -0.01677225 -0.00017619 ... -0.01937442 -0.02885394\n",
      "   0.01873207]\n",
      " ...\n",
      " [-0.00414984 -0.05026372 -0.01313511 ...  0.04619069  0.01732425\n",
      "   0.05234474]\n",
      " [-0.04485619  0.05247107 -0.01806646 ... -0.03655018 -0.01578962\n",
      "  -0.02526234]\n",
      " [ 0.05613489  0.03914652  0.03338869 ...  0.00439795 -0.05022417\n",
      "   0.0444719 ]]\n",
      "Intercept for 1st hidden layer\n",
      "[ 0.00316035  0.00316215 -0.00316216 ...  0.         -0.00316179\n",
      "  0.        ]\n",
      "Weights for 1st hidden layer\n",
      "[[ 0.01763007 -0.04463521 -0.01332723 ...  0.01907505 -0.04591683\n",
      "  -0.03357301]\n",
      " [-0.05646479 -0.02794462  0.02466994 ... -0.04323631  0.03094017\n",
      "  -0.00829903]\n",
      " [ 0.04937467 -0.04682774 -0.03273961 ... -0.025576    0.04883487\n",
      "   0.04264411]\n",
      " ...\n",
      " [-0.03612645  0.04613809  0.01880639 ...  0.01257409 -0.04612821\n",
      "   0.03193629]\n",
      " [ 0.04808385  0.03073177  0.04229087 ...  0.02400991  0.0273792\n",
      "  -0.01757417]\n",
      " [-0.03597354  0.03523282 -0.00460746 ...  0.03996522 -0.03010374\n",
      "  -0.03084861]]\n",
      "Intercept for 1st hidden layer\n",
      "[-0.00316215  0.00316144 -0.00316221 ... -0.00316168  0.00316206\n",
      "  0.0031622 ]\n",
      "Weights for 2nd hidden layer\n",
      "[[ 0.03305365  0.0252561   0.02514605 ...  0.03741397  0.03456805\n",
      "  -0.02552689]\n",
      " [-0.05007095 -0.02356059  0.0008706  ...  0.0426298   0.00704338\n",
      "  -0.02081943]\n",
      " [ 0.03437294 -0.01749428 -0.01347356 ... -0.01372872  0.00146197\n",
      "  -0.01034353]\n",
      " ...\n",
      " [-0.02656813 -0.04378494 -0.02034363 ...  0.00029852  0.015954\n",
      "   0.0158017 ]\n",
      " [-0.00279304 -0.04035658  0.02189073 ...  0.04174552 -0.00335266\n",
      "  -0.05505915]\n",
      " [-0.01378155 -0.02561566  0.03321515 ...  0.02158167 -0.02793461\n",
      "   0.02149392]]\n",
      "Intercept for 1st hidden layer\n",
      "[ 0.00316217  0.00316211  0.00316215 ...  0.00316196 -0.00304188\n",
      " -0.00316214]\n",
      "Weights for output layer\n",
      "[[-0.00887561  0.0282988   0.0614197  ... -0.01328466  0.02154142\n",
      "   0.0161912 ]\n",
      " [-0.06306908 -0.01396544  0.05643446 ... -0.07177685 -0.04175944\n",
      "  -0.05136869]\n",
      " [ 0.04323466  0.06941283  0.01351132 ... -0.01633263 -0.06718152\n",
      "  -0.0735596 ]\n",
      " ...\n",
      " [ 0.07068195  0.05143273  0.01483871 ... -0.07054432  0.00526116\n",
      "   0.07904867]\n",
      " [-0.0694308  -0.02776894 -0.01366667 ... -0.06869003 -0.0569225\n",
      "   0.06786231]\n",
      " [ 0.01097616  0.01328167  0.04679248 ... -0.06266124  0.03064598\n",
      "   0.05660903]]\n",
      "Intercept for output layer\n",
      "[-0.00316225  0.00316227  0.00316226  0.00316225 -0.00316224  0.00316225\n",
      " -0.00316227  0.00316217 -0.00316226 -0.00316225]\n"
     ]
    }
   ],
   "source": [
    "#       The assignment is to train with four hidden layers, each having\n",
    "# 1,024 nodes.  The activation function will be ReLU for the top two\n",
    "# layers, and linear for the bottom two layers (these lowest layer\n",
    "# receives the inputs).  We shall consider four datasets: MNIST fashion,\n",
    "# Cifar-10, cat/non-cat, and street view of digits. All groups will train\n",
    "# with 1,000 minibatches of size 128 for a total of 128,000 observations.\n",
    "\n",
    "# If 4, use regular NN with the street view of digits data.\n",
    "\n",
    "# Street View House Numbers (SVHN) Dataset\n",
    "# http://ufldl.stanford.edu/housenumbers/\n",
    "# import from SciPy\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "train_data=sio.loadmat('train_32x32.mat')\n",
    "test_data=sio.loadmat('test_32x32.mat')\n",
    "extra_data=sio.loadmat('extra_32x32.mat')\n",
    "\n",
    "x_train = train_data['X']\n",
    "y_train = train_data['y']\n",
    "x_test = test_data['X']\n",
    "y_test = test_data['y']\n",
    "x_extra = extra_data['X']\n",
    "y_extra = extra_data['y']\n",
    "\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_extra.shape)\n",
    "print(y_train.shape)\n",
    "print(y_extra.shape)\n",
    "# Use extra data as train data\n",
    "x_train = np.concatenate([x_train, x_extra],axis=3)\n",
    "y_train = np.concatenate([y_train, y_extra])\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(np.unique(y_test))\n",
    "\n",
    "\n",
    "\n",
    "x_train_1=x_train.reshape((604388, 32*32*3))\n",
    "print(x_train_1.shape)\n",
    "\n",
    "x_test_1=x_test.reshape((26032, 32*32*3))\n",
    "print(x_test_1.shape)\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "# define Keras model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Flatten\n",
    "\n",
    "\n",
    "x_train_1=x_train_1.astype('float32') / 255\n",
    "x_test_1=x_test_1.astype('float32') / 255\n",
    "y_train_m1=y_train\n",
    "y_train_m1[y_train_m1==10]=0\n",
    "y_test_m1=y_test\n",
    "y_test_m1[y_test_m1==10]=0\n",
    "y_train_fla=y_train_m1\n",
    "y_train_cat=to_categorical(y_train_fla)\n",
    "y_test_fla=y_test_m1\n",
    "y_test_cat=to_categorical(y_test_fla)\n",
    "\n",
    "from random import choices\n",
    "num=x_train_1.shape[0]\n",
    "a=range(num)\n",
    "print(a)\n",
    "#idx=choices(a, k=128000)\n",
    "idx=np.random.choice(a,128000,replace=False)\n",
    "print(len(np.unique(idx)))\n",
    "print(len(idx))\n",
    "\n",
    "x_train_final=x_train_1[idx,]\n",
    "y_train_final=y_train_cat[idx,]\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='relu',input_shape=(32 * 32 * 3,)))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(1024, activation='linear'))\n",
    "model.add(Dense(1024, activation='linear'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# compile keras model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "# model.fit(x_train_1, y_train_cat, batch_size=128, epochs=1)\n",
    "model.fit(x_train_final, y_train_final, batch_size=128, epochs=2)\n",
    "# results = model.evaluate(x_test_1, y_test_cat)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test_1, y_test_cat)\n",
    "print('test_acc:', test_acc)\n",
    "print('test_loss:', test_loss)\n",
    "\n",
    "#weights for 1st hidden layer\n",
    "print('Weights for 1st hidden layer')\n",
    "print(model.layers[0].get_weights()[0])\n",
    "#intercept for 1st hidden layer\n",
    "print(\"Intercept for 1st hidden layer\")\n",
    "print(model.layers[0].get_weights()[1])\n",
    "\n",
    "#weights for 2nd hidden layer\n",
    "print('Weights for 2nd hidden layer')\n",
    "print(model.layers[1].get_weights()[0])\n",
    "#intercept for 2nd hidden layer\n",
    "print(\"Intercept for 1st hidden layer\")\n",
    "print(model.layers[1].get_weights()[1])\n",
    "\n",
    "#weights for 3rd hidden layer\n",
    "print('Weights for 1st hidden layer')\n",
    "print(model.layers[2].get_weights()[0])\n",
    "#intercept for 1st hidden layer\n",
    "print(\"Intercept for 1st hidden layer\")\n",
    "print(model.layers[2].get_weights()[1])\n",
    "\n",
    "#weights for 4th hidden layer\n",
    "print('Weights for 2nd hidden layer')\n",
    "print(model.layers[3].get_weights()[0])\n",
    "#intercept for 2nd hidden layer\n",
    "print(\"Intercept for 1st hidden layer\")\n",
    "print(model.layers[3].get_weights()[1])\n",
    "\n",
    "#weights for output layer\n",
    "print('Weights for output layer')\n",
    "print(model.layers[4].get_weights()[0])\n",
    "#intercept for output layer\n",
    "print(\"Intercept for output layer\")\n",
    "print(model.layers[4].get_weights()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
