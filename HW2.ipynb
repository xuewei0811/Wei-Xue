{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requirement\n",
    "#For the homework due on Monday, September 9, I would like each team \n",
    "#to fit a fully connected feedforward network with two hidden layers, \n",
    "#where each hidden layer has 1,024 nodes.\n",
    "\n",
    "#If 9, fit the Street View House Numbers data using ReLU. (our # is 29)\n",
    "\n",
    "#Once you have trained the network, please submit through our class \n",
    "#website the following information:  Your accuracy on the test data set, \n",
    "#the time it took to train your network, and the trained network (with \n",
    "#all the weights and intercepts for each node).   I shall provide a \n",
    "#google form on our class website where you can submit that information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3, 73257)\n",
      "(32, 32, 3, 531131)\n",
      "(73257, 1)\n",
      "(531131, 1)\n",
      "(32, 32, 3, 604388)\n",
      "(604388, 1)\n",
      "(32, 32, 3, 26032)\n",
      "(26032, 1)\n",
      "[ 1  2  3  4  5  6  7  8  9 10]\n",
      "(604388, 3072)\n",
      "(26032, 3072)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [9]\n",
      " [2]\n",
      " ...\n",
      " [2]\n",
      " [1]\n",
      " [4]]\n",
      "(604388, 10)\n",
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "#load the data\n",
    "# 5. Street View House Numbers (SVHN) Dataset\n",
    "# http://ufldl.stanford.edu/housenumbers/\n",
    "# import from SciPy\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "train_data=sio.loadmat('train_32x32.mat')\n",
    "test_data=sio.loadmat('test_32x32.mat')\n",
    "extra_data=sio.loadmat('extra_32x32.mat')\n",
    "\n",
    "x_train = train_data['X']\n",
    "y_train = train_data['y']\n",
    "x_test = test_data['X']\n",
    "y_test = test_data['y']\n",
    "x_extra = extra_data['X']\n",
    "y_extra = extra_data['y']\n",
    "\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_extra.shape)\n",
    "print(y_train.shape)\n",
    "print(y_extra.shape)\n",
    "# Use extra data as train data\n",
    "x_train = np.concatenate([x_train, x_extra],axis=3)\n",
    "y_train = np.concatenate([y_train, y_extra])\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(np.unique(y_test))\n",
    "\n",
    "\n",
    "\n",
    "#x_train_partial=x_train[:,:,:,0:60439]\n",
    "#x_train_1=x_train_partial.reshape((60439, 32*32*3))\n",
    "x_train_1=x_train.reshape((604388, 32*32*3))\n",
    "print(x_train_1.shape)\n",
    "\n",
    "\n",
    "#x_test_partial=x_test[:,:,:,0:2603]\n",
    "#x_test_1=x_test_partial.reshape((2603, 32*32*3))\n",
    "x_test_1=x_test.reshape((26032, 32*32*3))\n",
    "print(x_test_1.shape)\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "# define Keras model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Flatten\n",
    "\n",
    "#x_train_1=x_train.reshape((604388, 32*32*3)\n",
    "x_train_1=x_train_1.astype('float32') / 255\n",
    "#x_test_1=x_test.reshape((26032, 32*32*3))\n",
    "x_test_1=x_test_1.astype('float32') / 255\n",
    "y_train_m1=np.copy(y_train)\n",
    "#y_test_m1=y_train\n",
    "y_train_m1[y_train_m1==10]=0\n",
    "#y_train_m1_partial=y_train_m1[0:60439,:]\n",
    "y_test_m1=np.copy(y_test)\n",
    "#y_test_m1=y_test\n",
    "y_test_m1[y_test_m1==10]=0\n",
    "#y_test_m1_partial=y_test_m1[0:2603,:]\n",
    "#y_train_fla=y_train_m1.flatten()\n",
    "#y_train_fla=y_train_m1_partial\n",
    "y_train_fla=np.copy(y_train_m1)\n",
    "#y_train_fla=y_train_m1\n",
    "y_train_cat=to_categorical(y_train_fla)\n",
    "#y_test_fla=y_test_m1\n",
    "y_test_fla=np.copy(y_test_m1)\n",
    "#y_test_fla=y_test_m1_partial\n",
    "#y_test_fla=y_test_m1.flatten()\n",
    "y_test_cat=to_categorical(y_test_fla)\n",
    "\n",
    "print(y_train_fla)\n",
    "print(y_train_cat.shape)\n",
    "print(np.unique(y_train_m1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0908 14:51:54.928500 4487394752 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0908 14:51:54.944764 4487394752 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0908 14:51:54.976101 4487394752 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0908 14:51:55.063349 4487394752 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0908 14:51:55.089871 4487394752 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0908 14:51:55.244165 4487394752 deprecation.py:323] From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0908 14:51:55.329760 4487394752 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "604388/604388 [==============================] - 98s 161us/step - loss: 13.3153 - acc: 0.1726\n",
      "Epoch 2/5\n",
      "604388/604388 [==============================] - 93s 154us/step - loss: 13.3334 - acc: 0.1728\n",
      "Epoch 3/5\n",
      "604388/604388 [==============================] - 96s 159us/step - loss: 13.3334 - acc: 0.1728\n",
      "Epoch 4/5\n",
      "604388/604388 [==============================] - 94s 155us/step - loss: 13.3334 - acc: 0.1728\n",
      "Epoch 5/5\n",
      "604388/604388 [==============================] - 94s 156us/step - loss: 13.3334 - acc: 0.1728\n",
      "26032/26032 [==============================] - 3s 118us/step\n",
      "26032/26032 [==============================] - 3s 106us/step\n",
      "test_acc: 0.1958743085433313\n",
      "test_loss: 12.960974645819778\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='relu',input_shape=(32 * 32 * 3,)))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# compile keras model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "# fit the keras model on the dataset\n",
    "#model.fit(x_train_1, y_train_cat, batch_size=128, epochs=5)\n",
    "model.fit(x_train_1, y_train_cat, batch_size=1024, epochs=5)\n",
    "results = model.evaluate(x_test_1, y_test_cat)\n",
    "\n",
    "#print(results)\n",
    "#print(model.metrics_names)\n",
    "test_loss, test_acc = model.evaluate(x_test_1, y_test_cat)\n",
    "print('test_acc:', test_acc)\n",
    "print('test_loss:', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights for 1st hidden layer\n",
      "[[ 1.0522465e-02 -1.4043618e-02 -3.1204492e-02 ...  1.4050596e-02\n",
      "   1.1647186e-02 -3.7377279e-02]\n",
      " [ 9.1072004e-03  1.2754792e-02 -9.7992150e-03 ... -2.7137410e-02\n",
      "   9.3547627e-05 -3.3123523e-02]\n",
      " [ 1.5395223e-02  2.8454669e-02 -1.4765278e-02 ...  3.9770611e-02\n",
      "  -8.0839433e-03  2.3467045e-02]\n",
      " ...\n",
      " [-5.3190701e-03  4.0327903e-02 -3.8459614e-02 ...  8.8878702e-03\n",
      "  -2.8149525e-02 -1.2112396e-02]\n",
      " [ 3.3947017e-02 -1.6440306e-02 -2.1226667e-02 ... -1.7458769e-03\n",
      "   2.1668760e-02  1.4322467e-02]\n",
      " [-4.4390708e-03 -2.4621667e-02  8.6124688e-03 ... -3.2901987e-02\n",
      "  -8.0372747e-03 -1.0644995e-02]]\n",
      "Intercept for 1st hidden layer\n",
      "[-0.00316146  0.0031619  -0.00316219 ...  0.00316105 -0.00316214\n",
      "  0.        ]\n",
      "Weights for 2nd hidden layer\n",
      "[[-0.05301954 -0.02937036  0.0135743  ... -0.03665827  0.00868513\n",
      "   0.01186578]\n",
      " [ 0.01731173  0.05342041 -0.04946553 ... -0.01933712  0.00125752\n",
      "  -0.00359508]\n",
      " [-0.02506833 -0.04257576  0.0493627  ...  0.04265726  0.04097372\n",
      "   0.04515155]\n",
      " ...\n",
      " [-0.0088836   0.04774784 -0.01755007 ...  0.01099301 -0.03496306\n",
      "   0.02204387]\n",
      " [-0.0430645   0.01930225 -0.02202693 ...  0.025604   -0.0201443\n",
      "  -0.0118319 ]\n",
      " [-0.02172149 -0.01117885  0.03275329 ... -0.0266256   0.04192123\n",
      "  -0.02055112]]\n",
      "Intercept for 1st hidden layer\n",
      "[-0.00316171  0.0031622  -0.00316213 ... -0.00314997 -0.00316214\n",
      " -0.00316222]\n",
      "Weights for output layer\n",
      "[[ 0.05825319 -0.05991352 -0.04707487 ... -0.00899391  0.01620131\n",
      "   0.0306194 ]\n",
      " [-0.06482607  0.05884149  0.04520801 ... -0.01115575 -0.05263638\n",
      "   0.05750189]\n",
      " [ 0.01962863  0.02274636 -0.0592299  ...  0.03613703  0.00949847\n",
      "   0.06149125]\n",
      " ...\n",
      " [-0.06442174  0.02786406  0.04235164 ... -0.01666451 -0.07049076\n",
      "  -0.074503  ]\n",
      " [ 0.02029157 -0.02921099 -0.04197383 ... -0.06097821 -0.03359339\n",
      "  -0.05177401]\n",
      " [-0.07178342 -0.03799361 -0.00452916 ... -0.06493206  0.01143741\n",
      "  -0.01891694]]\n",
      "Intercept for output layer\n",
      "[-0.00316134  0.00316227  0.00316225 -0.00316227  0.00316222  0.00316218\n",
      " -0.00316225  0.00316224 -0.00316226  0.00316189]\n"
     ]
    }
   ],
   "source": [
    "#weights for 1st hidden layer\n",
    "print('Weights for 1st hidden layer')\n",
    "print(model.layers[0].get_weights()[0])\n",
    "#intercept for 1st hidden layer\n",
    "print(\"Intercept for 1st hidden layer\")\n",
    "print(model.layers[0].get_weights()[1])\n",
    "\n",
    "#weights for 2nd hidden layer\n",
    "print('Weights for 2nd hidden layer')\n",
    "print(model.layers[1].get_weights()[0])\n",
    "#intercept for 2nd hidden layer\n",
    "print(\"Intercept for 1st hidden layer\")\n",
    "print(model.layers[1].get_weights()[1])\n",
    "\n",
    "#weights for output layer\n",
    "print('Weights for output layer')\n",
    "print(model.layers[2].get_weights()[0])\n",
    "#intercept for output layer\n",
    "print(\"Intercept for output layer\")\n",
    "print(model.layers[2].get_weights()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
